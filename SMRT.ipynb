{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GenerateDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def imbalanceBalancedDataset(ds, weights):\n",
    "    targets = np.array(ds.targets)\n",
    "    classes, class_counts = np.unique(targets, return_counts=True)\n",
    "    nb_classes = len(classes)\n",
    "    weights = list(np.int_(weights * (class_counts[0])))\n",
    "    class_indices = [np.where(targets == i)[0] for i in range(nb_classes)]\n",
    "    # Get imbalanced number of instances\n",
    "    imbal_class_indices = [class_idx[:class_count] for class_idx, class_count in zip(class_indices, weights)]\n",
    "    imbal_class_indices = np.hstack(imbal_class_indices)\n",
    "    \n",
    "    # Set target and data to dataset\n",
    "    ds.targets = targets[imbal_class_indices]\n",
    "    ds.data = ds.data[imbal_class_indices]\n",
    "    \n",
    "    return ds\n",
    "\n",
    "NUM_TRAIN = 44000\n",
    "NUM_VAL = 6000\n",
    "WEIGHTS = np.array([0.0, 0.0, 0.0, 0.1, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=T.ToTensor())\n",
    "cifar10_train.data = cifar10_train.data[:NUM_TRAIN]\n",
    "cifar10_train.targets = cifar10_train.targets[:NUM_TRAIN]\n",
    "imbalanceBalancedDataset(cifar10_train, WEIGHTS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ = cifar10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 07:19:26.803178 139801215850240 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:39: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "W0719 07:19:26.804279 139801215850240 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:40: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "W0719 07:19:26.805139 139801215850240 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:41: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "W0719 07:19:26.805896 139801215850240 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:42: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0719 07:19:26.806648 139801215850240 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:43: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from smrt.smrt.balance.smrt import smrt_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = dataset_.data.shape\n",
    "dataset_.data = dataset_.data.reshape(-1, x_shape[1] * x_shape[2] * x_shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3, 5, 6]), array([ 439, 4359, 4391]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = np.array(dataset_.targets)\n",
    "classes, class_counts = np.unique(targets, return_counts=True)\n",
    "classes, class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9189, 3072), (9189,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_.data.shape, dataset_.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 3072)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = dataset_.data[dataset_.targets == 3, :]\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([125, 125, 116, ..., 144, 116,  86], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docker/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed obs 3952 via VariationalAutoEncoder(activation_function='relu', batch_size=64,\n",
      "                       bias_strategy='zeros', clip=True, display_step=5,\n",
      "                       dropout=0.3, early_stopping=True, eps=1e-10,\n",
      "                       gclip_max=5.0, gclip_min=-5.0, l2_penalty=0.0001,\n",
      "                       layer_type='xavier', learning_function='adam',\n",
      "                       learning_rate=0.05, min_change=0.001, n_epochs=36,\n",
      "                       n_hidden=900, n_latent_factors=10,\n",
      "                       random_state=<smrt.smrt.utils.SeededRandomState object at 0x7f255c2912e8>,\n",
      "                       verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/docker/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed obs 32 via VariationalAutoEncoder(activation_function='relu', batch_size=64,\n",
      "                       bias_strategy='zeros', clip=True, display_step=5,\n",
      "                       dropout=0.3, early_stopping=True, eps=1e-10,\n",
      "                       gclip_max=5.0, gclip_min=-5.0, l2_penalty=0.0001,\n",
      "                       layer_type='xavier', learning_function='adam',\n",
      "                       learning_rate=0.05, min_change=0.001, n_epochs=36,\n",
      "                       n_hidden=900, n_latent_factors=10,\n",
      "                       random_state=<smrt.smrt.utils.SeededRandomState object at 0x7f255c2912e8>,\n",
      "                       verbose=0)\n"
     ]
    }
   ],
   "source": [
    "smrted = smrt_balance(dataset_.data, dataset_.targets,\n",
    "                      n_hidden=900,#[500,100,100,200],\n",
    "                      n_latent_factors=10,\n",
    "                      n_epochs=36,\n",
    "                      random_state=42,\n",
    "                      balance_ratio=1.0,\n",
    "                      shuffle=False,\n",
    "                      activation_function='relu',\n",
    "                      early_stopping=True,\n",
    "                      dropout=0.3,\n",
    "                      batch_size=64,\n",
    "                      learning_function='adam');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, ..., nan, nan, nan, nan])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smrted[0][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0719 07:38:34.692059 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:39: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
      "\n",
      "W0719 07:38:34.693703 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:40: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n",
      "\n",
      "W0719 07:38:34.694660 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:41: The name tf.train.AdagradDAOptimizer is deprecated. Please use tf.compat.v1.train.AdagradDAOptimizer instead.\n",
      "\n",
      "W0719 07:38:34.695671 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:42: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0719 07:38:34.696642 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:43: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "W0719 07:38:34.704659 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/base.py:171: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "W0719 07:38:34.724284 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/base.py:174: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0719 07:38:34.726831 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py:381: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0719 07:38:34.729689 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/layer.py:460: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0719 07:38:34.739628 140040194025216 deprecation.py:506] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/layer.py:365: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0719 07:38:34.804583 140040194025216 deprecation_wrapper.py:119] From /data/octavf/workspace/cifar/smrt/smrt/autoencode/layer.py:275: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0719 07:38:34.950471 140040194025216 deprecation.py:323] From /home/docker/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, cost=nan, time=0.2196 (sec)\n",
      "Epoch: 26, cost=nan, time=0.1036 (sec)\n",
      "Epoch: 51, cost=nan, time=0.1016 (sec)\n",
      "Epoch: 76, cost=nan, time=0.1014 (sec)\n",
      "Optimization complete after 100 epoch(s). Average epoch time: 0.1024 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VariationalAutoEncoder(activation_function='sigmoid', batch_size=64,\n",
       "                       bias_strategy='zeros', clip=False, display_step=25,\n",
       "                       dropout=0.2, early_stopping=False, eps=1e-09,\n",
       "                       gclip_max=5.0, gclip_min=-5.0, l2_penalty=None,\n",
       "                       layer_type='xavier', learning_function='adam',\n",
       "                       learning_rate=0.5, min_change=0.001, n_epochs=100,\n",
       "                       n_hidden=[3072, 100, 100, 100], n_latent_factors=3,\n",
       "                       random_state=42, verbose=2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smrt.smrt.autoencode import VariationalAutoEncoder\n",
    "\n",
    "v_encoder = VariationalAutoEncoder(n_epochs=100, n_hidden=[100,100,100], n_latent_factors=3, \n",
    "                                   learning_rate=0.5, batch_size=64, display_step=25, \n",
    "                                   activation_function='sigmoid', verbose=2, l2_penalty=None,\n",
    "                                   random_state=42, dropout=0.2, #early_stopping=True,\n",
    "                                   learning_function='adam', clip=False)\n",
    "\n",
    "v_encoder.fit(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-932c3a44aaa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py\u001b[0m in \u001b[0;36mgenerate_from_sample\u001b[0;34m(self, X, **nrm_args)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mz_mu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_sigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnrm_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/octavf/workspace/cifar/smrt/smrt/autoencode/autoencoder.py\u001b[0m in \u001b[0;36mfeed_forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopography_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNPDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;31m# z ~ N(0, I)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 542\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "fake = v_encoder.generate_from_sample(test_x[:10])\n",
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, nan, ..., nan, nan, nan, nan]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = v_encoder.generate()\n",
    "fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
